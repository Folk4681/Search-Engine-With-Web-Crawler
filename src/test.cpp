//C++ implementation of search engine using trie
#include <iostream> //used for input and output
#include <fstream> //used to read tokens and strings from input pages located in "inputs" folder
#include <regex> //this is used to parse the input; we delete any special characters from the input, and we separate each word in an input file into tokens, which is subsequently placed into a dynamic array
#include <cstring> //need this for strlen() function

#define NUM_INPUT_PAGES (9) //this is the number of input pages generated by webCrawler.py

#define ALPHABET_SIZE (63) //alphabet as seen by convert_char_to_int function

#define ARRAY_SIZE(a) sizeof(a)/sizeof(a[0])

using namespace std; //use standard namespace

 
vector<array<int,NUM_INPUT_PAGES>> arrayOfOccurrenceLists; //creates a dynamic-length 2-D array, where each element is an occurrence array of the frequency of a term in each input page; each array has the size of the number of input pages; not sorted in any order -> trie node leaves contain index information

static inline bool is_not_alnum_space(char c) //function to make sure a character is alphanumeric, including spaces
{
    return !(isalpha(c) || isdigit(c) || (c == ' '));
}

bool string_is_valid(const string &str) //function that traverses through each character and verifies that each character is alphanumeric including spaces
{
    return find_if(str.begin(), str.end(), is_not_alnum_space) == str.end();
}

void remove_duplicates(vector<string>& vec) //removes duplicate words from any given dynamic array of strings
{
  sort(vec.begin(), vec.end()); //we first sort the items alphabetically
  vec.erase(unique(vec.begin(), vec.end()), vec.end()); //we then search through it for duplicates
} //O(nlogn)


int convert_char_to_int(char c){ //this is my own encoding scheme, similar to UTF-encoding, except that I have made all the characters from 0-9,a-z,A-Z, have contiguous values. A-Z and a-z are treated the same.
	  int res;
	  if (isdigit(c))
	    res = c - '0';
	 
	  else if (isalpha(c)){
	    c = tolower(c);
	    res = (int) c - 87;
	  }
	  else
	    res = -1;
	  
	  return (res);

}

template<typename Out> //template is used to characterize any arbitrary data structure we use for a function
void split(const string &s, char delim, Out result) { //this function takes a string and separates it through all of its characters denoted by "delim"
    stringstream ss;
    ss.str(s);
    string item;// we essentially find where the delim occurs, and we split the string at that point
    while (getline(ss, item, delim)) {
        *(result++) = item;
    }
}

vector<string> split(const string &s, char delim) {// we use this function to split our entire input page into tokens/strings, which are kept inside a dynamic array
    vector<string> elems; //we use a dynamic array because we do not know the number of tokens in an input page ahead of time, in which case we could just use a regular fixed-length array
    split(s, delim, back_inserter(elems));
    return elems;
}

struct intBucket { //this is used a simple tuple integer pair; we use this to sort through returning search result pages, and rank them according to the page with the highest frequency of a word
	int value; //value = frequency of word in page
	int index; //index = input page number
	intBucket(int v, int i): value(v), index(i) {}
};

struct less_than_key{ //we use this struct to order the intBucket accordingly
	inline bool operator() (const intBucket& i, const intBucket& j){
		return (i.value < j.value); //we sort "intBuckets" by their parameters "value", not "index" (we want the pages with a specific highest frequency word to appear before other pages
	}
};

struct TrieNode { //this is our basic trie node
	struct TrieNode *children[ALPHABET_SIZE]; //every node can have a maximum of ALPHABET_SIZE children
	bool isExternal; //this lets us know if a node is a leaf or not
	int occurrenceListIndex; //as on page 679 of the textbook, every leaf should contain the index the word's frequencies are located at, in "arrayOfOccurenceLists"
	
};

struct TrieNode *makeNode(void){  //we use this struct only to create nodes of a trie
	struct TrieNode *node = NULL; //initialize node to be null
 
    	node = (struct TrieNode *)malloc(sizeof(struct TrieNode)); //allocate memory to the node so it has sufficient space
 
	if (node){
		int i;
		node->isExternal = false; //initialize node's children, and initially make node not a leaf
		for (i = 0; i < ALPHABET_SIZE; i++)
		    node->children[i] = NULL;
	}
	 
	return node;
}

void insert(struct TrieNode *root, const char *key, int pageNumber){
	int level; //level is the depth of the trie
	int length = strlen(key); //this gives us the number of levels down we need to go
    	int index; //this gives us the index of the occurrence list to use
	pageNumber = pageNumber-1;
 
    	struct TrieNode *node = root;
 
    	for (level = 0; level < length; level++){
        	index = convert_char_to_int(key[level]); //we use numbers instead of characters
        	if (!node->children[index]) //if we reached the end of the word so far, then create the rest of the characters
            		node->children[index] = makeNode();
         	node = node->children[index]; //keep going until we are at the end of the word
    	}
 	if (node->isExternal==true){ //if this word already exists, then increment its frequency
		//cout << pageNumber << endl;
		arrayOfOccurrenceLists.at(node->occurrenceListIndex)[pageNumber]++;
	}
	else{ //if word does not already exist, initialize its frequency, arrayOfOccurrenceList index, and set its isExternal parameter to true
		int preArray[NUM_INPUT_PAGES];
		for (int i = 0; i<NUM_INPUT_PAGES; i++){
			preArray[i] = (i==pageNumber);
		}
		array<int,NUM_INPUT_PAGES> array; //this is a container that encapsulates fixed-size arrays
		copy(begin(preArray), end(preArray), begin(array)); //we can perform different functions on it, like equating two different arrays
		node->occurrenceListIndex = arrayOfOccurrenceLists.size();
		arrayOfOccurrenceLists.push_back(array);
		node->isExternal = true;
	}
    // mark last node as leaf
 	
}

void search(struct TrieNode *root, const char *key){
    	int level; //level is depth of tree
    	int length; //length is length of key
    	int index;
	int next=0;
	const char* str;
	int moreInput; //this tells us if there are more children of the node left
    	struct TrieNode *node;
 	vector<string> tokens = split(key, ' '); //we create a vector out of the search query, based on the number of spaces
	int array[NUM_INPUT_PAGES][tokens.size()]; //this 2-D array keeps track of the frequencies of each token in the trie
	remove_duplicates(tokens);//we remove any duplicates from the search query
	vector<string> stop_words = {"a","about","above","across","after","against","along","among","and","around",
	"at","before","behind","between","beyond","but","by","concerning","despite","down","during","including",
	"except","few","following","for","from","he","he","her","him","i","in","into","it","like","me","near","of",
	"off","on","one","out","over","plus","she","since","some","them","the","they",
	"through","throughout","to","towards","under","until","up","upon","us","we","with","within","without","you"};
	for (int i=0; i<tokens.size(); i++){
		node = root;//we initialize node to be root
		moreInput = 0;
		str = tokens.at(i).c_str(); //convert string of token to const char*
		length = strlen(str);
	    	for (level = 0; level < length; level++){
			index = convert_char_to_int(str[level]);
			if (!node->children[index]){//keep going until we reached the end of the token; if there are no more letters to go through in the trie, but there is still more of the token to traverse through, then break out of loop and say that the word was not found
				moreInput = 1;
		   		break;
	 		}
			node = node->children[index];		
	   	}
		
		if (node->isExternal && !moreInput)//if the word was found, then make sure the frequencies are saved in our 2-D array
			for (int j=0; j<NUM_INPUT_PAGES; j++)
				array[j][i] = arrayOfOccurrenceLists.at(node->occurrenceListIndex)[j];
		else{
			string lowercase = tokens.at(i); //if word was not found, check if it is a stop word, and state that it was not found, set all its frequencies to zero
			transform(lowercase.begin(), lowercase.end(), lowercase.begin(), ::tolower);
			for(int k=0; k<stop_words.size(); k++){
				if (!lowercase.compare(stop_words.at(k))){
					cout << "The word \"" << str << "\" is a stop word, and is not included in the search." << endl;
					next=1;
			}
	   	}
			for (int j=0; j<NUM_INPUT_PAGES; j++)
					array[j][i] = 0;
			
			if(next==1) {next=0; continue;}
			cout << "The word \"" << str << "\" is not found in any of the input pages." << endl;
		}

	}
	vector<intBucket> finalVec; //sum up the frequencies, and output them in a sorted order, based on the highest frequencies
	for (int i = 0; i<NUM_INPUT_PAGES; i++){
		finalVec.push_back(intBucket(0,i));
		for (int j=0; j<tokens.size(); j++){
			finalVec.at(i).value += array[i][j];
			
		}
			
	}
	sort(finalVec.begin(), finalVec.end(), less_than_key());
	for (int i = finalVec.size()-1; i>=0; i--)
		if(finalVec.at(i).value!=0)
			cout << "The number of hits for input page #" << finalVec.at(i).index+1 << " is: " << finalVec.at(i).value << "." << endl;
}



int main()
{	
	struct TrieNode *root = makeNode(); //create the root node

	for (int i=1; i <= NUM_INPUT_PAGES; i++){
		string addr = "inputs/input" + to_string(i) + ".txt"; //all input pages have this file address
		ifstream t(addr);
		stringstream buffer;
		buffer << t.rdbuf();// this extracts the contents from the txt files, and puts them into a string variable called "contents"
		string contents = buffer.str();
		char const *str;
		vector<string> tokens = split(contents, ' '); //call the split function initialized earlier and split the "contents" into a list of tokens/words, for each space encountered

		int x=0;
		for (int j=0; j<tokens.size(); j++){ //insert each token into the trie, denoting each input page number
			//cout << tokens.at(j).c_str() << endl;
			insert(root, tokens.at(j).c_str(), i);
		}
		cout << "Crawled " << i << " page(s) so far." << endl;
		cout << "----------------" << endl;
	}
	
	string input;
	

	while (true){ //start query process
		struct timespec start, finish; double elapsed;
		cout << "Search something on the input pages (q to quit): ";
		getline(cin,input);
		if(input=="q") break;
		while(!string_is_valid(input) || input.find(" ")==0){ //if the query begins with a space, this is not a valid search
			cout << "Invalid input. You can only use alphanumeric characters, with spaces in between multiple tokens. Try again: ";
			cin.clear();
			getline(cin, input);
			cout << endl;
		} //once we get a valid search query, start the timer
		
		clock_gettime(CLOCK_REALTIME, &start);
		search(root,input.c_str()); //search for the word in the trie
		clock_gettime(CLOCK_REALTIME, &finish); //stop the timer, and display the time it took to find the results in the trie
		elapsed = (finish.tv_sec - start.tv_sec);
		elapsed += (finish.tv_nsec - start.tv_nsec) / 1000000000.0;
		cout << "Search time to produce results: " << elapsed << " seconds" << endl;
		cout << endl;
		cin.clear();


	}

	
	
 
    	return 0;
}
